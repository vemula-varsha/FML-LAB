{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOen+gWBDaqefUPLJEdAtmf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vemula-varsha/FML-LAB/blob/main/tokenization_stemm_lemmatize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization using python split() function**"
      ],
      "metadata": {
        "id": "STrOkRTJV4WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#word_tokenization\n",
        "text='''once upon a time there is a kingdom called vyasharya, the one who was ruling that kingdom was mahavir rajput ,a great man with dignistic personality. He was peoples person. He loves to help people who are in need. Becoz of him vyasharya became a greenary and healthy city.'''\n",
        "tokens=text.split()\n",
        "print(tokens)\n",
        "print(\"No.of tokens: \",len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZTubZ6UWEGK",
        "outputId": "e299568c-c1c0-4e4c-d4e5-ad2a13359a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['once', 'upon', 'a', 'time', 'there', 'is', 'a', 'kingdom', 'called', 'vyasharya,', 'the', 'one', 'who', 'was', 'ruling', 'that', 'kingdom', 'was', 'mahavir', 'rajput', ',a', 'great', 'man', 'with', 'dignistic', 'personality.', 'He', 'was', 'peoples', 'person.', 'He', 'loves', 'to', 'help', 'people', 'who', 'are', 'in', 'need.', 'Becoz', 'of', 'him', 'vyasharya', 'became', 'a', 'greenary', 'and', 'healthy', 'city.']\n",
            "No.of tokens:  49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence_tokenization\n",
        "text='''once upon a time there is a kingdom called vyasharya, the one who was ruling that kingdom was mahavir rajput ,a great man with dignistic personality. He was peoples person. He loves to help people who are in need. Becoz of him vyasharya became a greenary and healthy city.'''\n",
        "sentences=text.split('.')\n",
        "print(sentences)\n",
        "print(\"No.of sentences: \",len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp_PV4NZYlK9",
        "outputId": "b80b4f84-3620-438b-f989-72759f70cebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['once upon a time there is a kingdom called vyasharya, the one who was ruling that kingdom was mahavir rajput ,a great man with dignistic personality', ' He was peoples person', ' He loves to help people who are in need', ' Becoz of him vyasharya became a greenary and healthy city', '']\n",
            "No.of sentences:  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization using Regular expressions**"
      ],
      "metadata": {
        "id": "A1HJQFQqZoe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "RlFWbi3HZQG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word tokenization\n",
        "tokens = re.findall(\"[\\w']+\", text)\n",
        "print(tokens)\n",
        "print(\"No.of tokens : \", len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUj048IsZni9",
        "outputId": "1304cfff-a33e-4518-c394-e9f3b77e44dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['once', 'upon', 'a', 'time', 'there', 'is', 'a', 'kingdom', 'called', 'vyasharya', 'the', 'one', 'who', 'was', 'ruling', 'that', 'kingdom', 'was', 'mahavir', 'rajput', 'a', 'great', 'man', 'with', 'dignistic', 'personality', 'He', 'was', 'peoples', 'person', 'He', 'loves', 'to', 'help', 'people', 'who', 'are', 'in', 'need', 'Becoz', 'of', 'him', 'vyasharya', 'became', 'a', 'greenary', 'and', 'healthy', 'city']\n",
            "No.of tokens :  49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence tokenization\n",
        "sentences = re.compile('[.?!] ').split(text)\n",
        "print(sentences)\n",
        "print(\"No.of sentences : \", len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aci6WFReZ-ye",
        "outputId": "c62e073b-4d73-48b0-c6e2-6f7be4e435d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['once upon a time there is a kingdom called vyasharya, the one who was ruling that kingdom was mahavir rajput ,a great man with dignistic personality', 'He was peoples person', 'He loves to help people who are in need', 'Becoz of him vyasharya became a greenary and healthy city.']\n",
            "No.of sentences :  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization using NLTK**"
      ],
      "metadata": {
        "id": "qL0sFfmjbYq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDV2np79bYb2",
        "outputId": "17d42e44-4672-486f-8b8e-179b66fb79ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoHcXhPUbL-m",
        "outputId": "c42cfc49-8b02-4b9f-bca2-27eed37faded"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokens=word_tokenize(text)\n",
        "print(tokens)\n",
        "print(\"No.Of Tokens: \",len(tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEI3IjBGbwJO",
        "outputId": "474a15ed-b12b-49a2-d6bd-9defe76e6428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['once', 'upon', 'a', 'time', 'there', 'is', 'a', 'kingdom', 'called', 'vyasharya', ',', 'the', 'one', 'who', 'was', 'ruling', 'that', 'kingdom', 'was', 'mahavir', 'rajput', ',', 'a', 'great', 'man', 'with', 'dignistic', 'personality', '.', 'He', 'was', 'peoples', 'person', '.', 'He', 'loves', 'to', 'help', 'people', 'who', 'are', 'in', 'need', '.', 'Becoz', 'of', 'him', 'vyasharya', 'became', 'a', 'greenary', 'and', 'healthy', 'city', '.']\n",
            "No.Of Tokens:  55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize\n",
        "sentence=sent_tokenize(text)\n",
        "print(sentence)\n",
        "print(\"No of sentences: \",len(sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCyqQn7Scawm",
        "outputId": "a9e3e5dd-5161-4bb9-d94c-79c2c41388c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['once upon a time there is a kingdom called vyasharya, the one who was ruling that kingdom was mahavir rajput ,a great man with dignistic personality.', 'He was peoples person.', 'He loves to help people who are in need.', 'Becoz of him vyasharya became a greenary and healthy city.']\n",
            "No of sentences:  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk .stem import PorterStemmer\n"
      ],
      "metadata": {
        "id": "dIIeQ4PzcvEG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "print(porter.stem(\"cats\"))\n",
        "print(porter.stem(\"troubling\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNgbBj6JLW_O",
        "outputId": "c34c7cf0-7359-477f-bbcf-fcd86c8ab615"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "troubl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## create a function which takes a sentence and returns the stemmed sentence."
      ],
      "metadata": {
        "id": "sX0TXVuwLd_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "\n",
        "sentence=\"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\"\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "def stemSentence(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    print(token_words)\n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)\n",
        "\n",
        "x=stemSentence(sentence)\n",
        "print(\"Sentence after stemming :\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIrCAXF5Lb4d",
        "outputId": "6d8e2edf-9077-4d85-afbc-03f72037e764"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pythoners', 'are', 'very', 'intelligent', 'and', 'work', 'very', 'pythonly', 'and', 'now', 'they', 'are', 'pythoning', 'their', 'way', 'to', 'success', '.']\n",
            "Sentence after stemming : python are veri intellig and work veri pythonli and now they are python their way to success . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HjjsIPkMbIn",
        "outputId": "916c82e0-b080-43bb-a3d7-71c35946784c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
        "punctuations=\"?:!.,;\"\n",
        "token_words = nltk.word_tokenize(sentence)\n",
        "print(token_words)\n",
        "\n",
        "lemma_sentence=[]\n",
        "for word in token_words:\n",
        "  lemma_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "  lemma_sentence.append(\" \")\n",
        "\n",
        "print(\"lemmas of tokens: \", ''.join(lemma_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bq1Z0X1MN1w",
        "outputId": "b5125e0b-2039-49de-ac7a-aede031544dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He', 'was', 'running', 'and', 'eating', 'at', 'same', 'time', '.', 'He', 'has', 'bad', 'habit', 'of', 'swimming', 'after', 'playing', 'long', 'hours', 'in', 'the', 'Sun', '.']\n",
            "lemmas of tokens:  He wa running and eating at same time . He ha bad habit of swimming after playing long hour in the Sun . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kp5Bm9ZRMmSC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}